{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6YZSCrWXPL39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dca83e8f-8190-4e23-a1c7-bd70f5e099cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-637e38d7caa2>:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data['Numeric'].fillna(data['Numeric'].mean(), inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Random Forest model and scaler saved successfully.\n",
            "Model: Logistic Regression\n",
            "Accuracy: 0.9889\n",
            "Precision: 0.9896\n",
            "Recall: 0.9882\n",
            "F1 Score: 0.9889\n",
            "ROC AUC: 0.9889\n",
            "Confusion Matrix:\n",
            "[[1427   15]\n",
            " [  17 1425]]\n",
            "\n",
            "\n",
            "Model: Random Forest\n",
            "Accuracy: 0.9976\n",
            "Precision: 0.9986\n",
            "Recall: 0.9965\n",
            "F1 Score: 0.9976\n",
            "ROC AUC: 0.9976\n",
            "Confusion Matrix:\n",
            "[[1440    2]\n",
            " [   5 1437]]\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_predict, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "import joblib\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Install imbalanced-learn if not already installed\n",
        "# !pip install imbalanced-learn\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/content/drive/My Drive/Handwashing with soap.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Preprocessing\n",
        "# Drop columns with mostly missing values\n",
        "data = data.drop(columns=['Low', 'High', 'Comments'])\n",
        "\n",
        "# Fill missing values for numeric columns\n",
        "data['Numeric'].fillna(data['Numeric'].mean(), inplace=True)\n",
        "\n",
        "# Encode categorical variables\n",
        "label_encoder = LabelEncoder()\n",
        "data['Country'] = label_encoder.fit_transform(data['Country'])\n",
        "data['WHO region'] = label_encoder.fit_transform(data['WHO region'])\n",
        "data['Residence Area Type'] = label_encoder.fit_transform(data['Residence Area Type'])\n",
        "\n",
        "# Define target and features\n",
        "# Creating a binary target variable based on handwashing coverage (Numeric column) with a 50% threshold\n",
        "threshold = 50\n",
        "data['handwashing_category'] = (data['Numeric'] > threshold).astype(int)  # 1 for above 50%, 0 for below 50%\n",
        "\n",
        "# Selecting relevant features\n",
        "X = data[['Year', 'Country', 'WHO region', 'Residence Area Type', 'Display Value']]\n",
        "y = data['handwashing_category']\n",
        "\n",
        "# Handle class imbalance using SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "\n",
        "# Define the models and their hyperparameters for tuning\n",
        "param_grid_rf = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "param_grid_lr = {'C': [0.01, 0.1, 1, 10, 100]}\n",
        "\n",
        "# Define models with GridSearchCV\n",
        "models = {\n",
        "    'Logistic Regression': GridSearchCV(LogisticRegression(max_iter=500), param_grid_lr, cv=5),\n",
        "    'Random Forest': GridSearchCV(RandomForestClassifier(), param_grid_rf, cv=5)\n",
        "}\n",
        "\n",
        "# Dictionary for storing results\n",
        "results = {}\n",
        "\n",
        "# K-Fold Cross Validation and Metrics Calculation\n",
        "for name, model in models.items():\n",
        "    # Define a pipeline with scaling and the model\n",
        "    pipeline = ImbPipeline([\n",
        "        ('scaler', StandardScaler()),  # Standardize the features\n",
        "        ('model', model)  # Model with hyperparameter tuning\n",
        "    ])\n",
        "\n",
        "    # Fit the pipeline\n",
        "    pipeline.fit(X_resampled, y_resampled)\n",
        "\n",
        "    # Cross-validation prediction\n",
        "    y_pred = cross_val_predict(pipeline, X_resampled, y_resampled, cv=5)\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y_resampled, y_pred)\n",
        "    precision = precision_score(y_resampled, y_pred)\n",
        "    recall = recall_score(y_resampled, y_pred)\n",
        "    f1 = f1_score(y_resampled, y_pred)\n",
        "    roc_auc = roc_auc_score(y_resampled, y_pred)\n",
        "    conf_matrix = confusion_matrix(y_resampled, y_pred)\n",
        "\n",
        "    # Store results\n",
        "    results[name] = {\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1 Score': f1,\n",
        "        'ROC AUC': roc_auc,\n",
        "        'Confusion Matrix': conf_matrix\n",
        "    }\n",
        "\n",
        "    # Save the best estimator if it's Random Forest\n",
        "    if name == 'Random Forest':\n",
        "        best_rf_model = model.best_estimator_\n",
        "        scaler = StandardScaler().fit(X_resampled)\n",
        "        joblib.dump(best_rf_model, '/content/drive/My Drive/best_rf_model.pkl')\n",
        "        joblib.dump(scaler, '/content/drive/My Drive/scaler.pkl')\n",
        "        print(\"Best Random Forest model and scaler saved successfully.\")\n",
        "\n",
        "# Display enhanced results\n",
        "for model_name, metrics in results.items():\n",
        "    print(f\"Model: {model_name}\")\n",
        "    print(f\"Accuracy: {metrics['Accuracy']:.4f}\")\n",
        "    print(f\"Precision: {metrics['Precision']:.4f}\")\n",
        "    print(f\"Recall: {metrics['Recall']:.4f}\")\n",
        "    print(f\"F1 Score: {metrics['F1 Score']:.4f}\")\n",
        "    print(f\"ROC AUC: {metrics['ROC AUC']:.4f}\")\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(metrics['Confusion Matrix'])\n",
        "    print(\"\\n\")\n"
      ]
    }
  ]
}